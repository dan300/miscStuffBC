{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:52:37.017035Z",
     "start_time": "2025-03-11T21:52:37.010864Z"
    }
   },
   "cell_type": "code",
   "source": "print(common_rows)",
   "id": "670b84469457886b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   query total_clicks total_impressions  \\\n",
      "0                          brokerchooser       42,766           390,355   \n",
      "1                     trading 212 review       11,285           241,417   \n",
      "2                    interactive brokers        9,059           708,432   \n",
      "3                                revolut        8,447           596,897   \n",
      "4                         broker chooser        8,372            75,277   \n",
      "...                                  ...          ...               ...   \n",
      "8635              is kot4x a good broker            2                77   \n",
      "8644  does fidelity charge a monthly fee            2                19   \n",
      "8647            routing number 042200910            2                 4   \n",
      "8656                  how safe is etrade            2               154   \n",
      "8661      is sofi a safe place to invest            2                44   \n",
      "\n",
      "                                                top_url       content_type  \n",
      "0                            https://brokerchooser.com/           Homepage  \n",
      "1     https://brokerchooser.com/broker-reviews/tradi...      Broker_review  \n",
      "2     https://brokerchooser.com/broker-reviews/inter...      Broker_review  \n",
      "3     https://brokerchooser.com/broker-reviews/revol...      Broker_review  \n",
      "4                            https://brokerchooser.com/           Homepage  \n",
      "...                                                 ...                ...  \n",
      "8635  https://brokerchooser.com/safety/kot4x-broker-...  Safety_megascaled  \n",
      "8644  https://brokerchooser.com/broker-reviews/fidel...      Broker_review  \n",
      "8647  https://brokerchooser.com/safety/first-financi...  Safety_megascaled  \n",
      "8656  https://brokerchooser.com/broker-reviews/e-tra...      Broker_review  \n",
      "8661  https://brokerchooser.com/broker-reviews/sofi-...      Broker_review  \n",
      "\n",
      "[3396 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:52:48.242295Z",
     "start_time": "2025-03-11T21:52:48.199493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 2 CSV files\n",
    "jan_df = pd.read_csv('data/usa-january.csv')\n",
    "feb_df = pd.read_csv('data/usa-february.csv')\n",
    "# csv_file1 = pd.read_csv('data/gsc-with-categories-january.csv')\n",
    "# csv_file2 = pd.read_csv('data/gsc-with-categories-february.csv')\n",
    "\n",
    "# Get a boolean value whether each row is in the column of another DataFrame\n",
    "is_in_both = jan_df['query'].isin(feb_df['query'])\n",
    "\n",
    "# Get rows which are in both files\n",
    "common_rows = csv_file1[is_in_both]\n",
    "\n",
    "# Export to CSV\n",
    "# common_rows.to_csv('data/usa-january-february-common.csv', index=False)\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:56:26.219505Z",
     "start_time": "2025-03-11T21:56:21.638240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files and convert numeric columns\n",
    "# jan_df = pd.read_csv('january_data.csv')\n",
    "# feb_df = pd.read_csv('february_data.csv')\n",
    "\n",
    "# Convert string columns to numeric\n",
    "numeric_columns = ['total_clicks', 'total_impressions']\n",
    "jan_df[numeric_columns] = jan_df[numeric_columns].replace({',': ''}, regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "feb_df[numeric_columns] = feb_df[numeric_columns].replace({',': ''}, regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "# Assuming common_rows is already created and contains the common queries\n",
    "# If you need to create common_rows:\n",
    "# common_rows = pd.DataFrame({'query': list(set(jan_df['query']).intersection(set(feb_df['query'])))})\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Add the query column from common_rows\n",
    "result_df['query'] = common_rows['query']\n",
    "\n",
    "# For each common query, find the data in both January and February\n",
    "for index, row in result_df.iterrows():\n",
    "    query = row['query']\n",
    "    \n",
    "    # Get the January and February data for this query\n",
    "    jan_row = jan_df.loc[jan_df['query'] == query].iloc[0]\n",
    "    feb_row = feb_df.loc[feb_df['query'] == query].iloc[0]\n",
    "    \n",
    "    # Calculate differences\n",
    "    click_diff = feb_row['total_clicks'] - jan_row['total_clicks']\n",
    "    impression_diff = feb_row['total_impressions'] - jan_row['total_impressions']\n",
    "    \n",
    "    # Use January's top_url and content_type\n",
    "    top_url = jan_row['top_url']\n",
    "    content_type = jan_row['content_type']\n",
    "    \n",
    "    # Add to result DataFrame\n",
    "    result_df.at[index, 'jan_clicks'] = jan_row['total_clicks']\n",
    "    result_df.at[index, 'feb_clicks'] = feb_row['total_clicks']\n",
    "    result_df.at[index, 'click_diff'] = click_diff\n",
    "    result_df.at[index, 'click_pct_change'] = (click_diff / jan_row['total_clicks'] * 100) if jan_row['total_clicks'] > 0 else None\n",
    "    \n",
    "    result_df.at[index, 'jan_impressions'] = jan_row['total_impressions']\n",
    "    result_df.at[index, 'feb_impressions'] = feb_row['total_impressions']\n",
    "    result_df.at[index, 'impression_diff'] = impression_diff\n",
    "    result_df.at[index, 'impression_pct_change'] = (impression_diff / jan_row['total_impressions'] * 100) if jan_row['total_impressions'] > 0 else None\n",
    "    \n",
    "    result_df.at[index, 'top_url'] = top_url\n",
    "    result_df.at[index, 'content_type'] = content_type\n",
    "\n",
    "# Sort by click difference in descending order\n",
    "result_df = result_df.sort_values(by='click_diff', ascending=False)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "result_df.to_csv('data/query_comparison_jan_feb.csv', index=False)\n",
    "\n",
    "print(f\"Comparison completed. Found {len(result_df)} common queries.\")\n",
    "print(\"Top 5 queries with biggest click increases:\")\n",
    "print(result_df.head(5)[['query', 'click_diff', 'click_pct_change']])"
   ],
   "id": "acc8816faa488b54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison completed. Found 3396 common queries.\n",
      "Top 5 queries with biggest click increases:\n",
      "                           query  click_diff  click_pct_change\n",
      "0                  brokerchooser         0.0               0.0\n",
      "4314           brokers in mexico         0.0               0.0\n",
      "4318  when is google stock split         0.0               0.0\n",
      "4322  where can you short stocks         0.0               0.0\n",
      "4324          what is qfs ledger         0.0               0.0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:49:41.775814Z",
     "start_time": "2025-03-11T21:49:41.767806Z"
    }
   },
   "cell_type": "code",
   "source": "print(common_rows)\n",
   "id": "c0d6627718575f46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   query total_clicks total_impressions  \\\n",
      "0                          brokerchooser       42,766           390,355   \n",
      "1                     trading 212 review       11,285           241,417   \n",
      "2                    interactive brokers        9,059           708,432   \n",
      "3                                revolut        8,447           596,897   \n",
      "4                         broker chooser        8,372            75,277   \n",
      "...                                  ...          ...               ...   \n",
      "8635              is kot4x a good broker            2                77   \n",
      "8644  does fidelity charge a monthly fee            2                19   \n",
      "8647            routing number 042200910            2                 4   \n",
      "8656                  how safe is etrade            2               154   \n",
      "8661      is sofi a safe place to invest            2                44   \n",
      "\n",
      "                                                top_url       content_type  \n",
      "0                            https://brokerchooser.com/           Homepage  \n",
      "1     https://brokerchooser.com/broker-reviews/tradi...      Broker_review  \n",
      "2     https://brokerchooser.com/broker-reviews/inter...      Broker_review  \n",
      "3     https://brokerchooser.com/broker-reviews/revol...      Broker_review  \n",
      "4                            https://brokerchooser.com/           Homepage  \n",
      "...                                                 ...                ...  \n",
      "8635  https://brokerchooser.com/safety/kot4x-broker-...  Safety_megascaled  \n",
      "8644  https://brokerchooser.com/broker-reviews/fidel...      Broker_review  \n",
      "8647  https://brokerchooser.com/safety/first-financi...  Safety_megascaled  \n",
      "8656  https://brokerchooser.com/broker-reviews/e-tra...      Broker_review  \n",
      "8661  https://brokerchooser.com/broker-reviews/sofi-...      Broker_review  \n",
      "\n",
      "[3396 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T22:41:51.420728Z",
     "start_time": "2025-03-11T22:41:51.381586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "jan_df = pd.read_csv('data/category-gsc-january.csv')\n",
    "feb_df = pd.read_csv('data/category-gsc-february.csv')\n",
    "\n",
    "# Convert percentage strings to numeric values if needed\n",
    "for df in [jan_df, feb_df]:\n",
    "    if df['ctr_percentage'].dtype == 'object':\n",
    "        df['ctr_percentage'] = df['ctr_percentage'].str.replace('%', '').astype(float)\n",
    "    \n",
    "    # Also handle numeric columns with commas if present\n",
    "    for col in ['total_clicks', 'total_impressions', 'unique_urls']:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.replace(',', '').astype(float)\n",
    "\n",
    "# Create a new dataframe with all unique content types\n",
    "all_categories = pd.concat([jan_df['content_type'], feb_df['content_type']]).unique()\n",
    "result_df = pd.DataFrame({'content_type': all_categories})\n",
    "\n",
    "# Add January data\n",
    "result_df = result_df.merge(\n",
    "    jan_df[['content_type', 'total_clicks', 'total_impressions', 'ctr_percentage']], \n",
    "    on='content_type', \n",
    "    how='left',\n",
    "    suffixes=('', '_jan')\n",
    ")\n",
    "\n",
    "# Rename columns for January\n",
    "result_df.rename(columns={\n",
    "    'total_clicks': 'jan_clicks',\n",
    "    'total_impressions': 'jan_impressions',\n",
    "    'ctr_percentage': 'jan_ctr'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add February data\n",
    "result_df = result_df.merge(\n",
    "    feb_df[['content_type', 'total_clicks', 'total_impressions', 'ctr_percentage']], \n",
    "    on='content_type', \n",
    "    how='left',\n",
    "    suffixes=('', '_feb')\n",
    ")\n",
    "\n",
    "# Rename columns for February\n",
    "result_df.rename(columns={\n",
    "    'total_clicks': 'feb_clicks',\n",
    "    'total_impressions': 'feb_impressions',\n",
    "    'ctr_percentage': 'feb_ctr'\n",
    "}, inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 for categories that don't exist in one of the months\n",
    "result_df = result_df.fillna(0)\n",
    "\n",
    "# Calculate differences\n",
    "result_df['clicks_diff'] = result_df['feb_clicks'] - result_df['jan_clicks']\n",
    "result_df['impressions_diff'] = result_df['feb_impressions'] - result_df['jan_impressions']\n",
    "result_df['ctr_diff'] = result_df['feb_ctr'] - result_df['jan_ctr']\n",
    "\n",
    "# Calculate percentage changes\n",
    "result_df['clicks_pct_change'] = result_df.apply(\n",
    "    lambda x: ((x['feb_clicks'] - x['jan_clicks']) / x['jan_clicks'] * 100) if x['jan_clicks'] > 0 else float('inf'),\n",
    "    axis=1\n",
    ")\n",
    "result_df['impressions_pct_change'] = result_df.apply(\n",
    "    lambda x: ((x['feb_impressions'] - x['jan_impressions']) / x['jan_impressions'] * 100) if x['jan_impressions'] > 0 else float('inf'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Round all numeric columns to 2 decimal places\n",
    "numeric_cols = result_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "result_df[numeric_cols] = result_df[numeric_cols].round(2)\n",
    "\n",
    "# Replace infinity values with None for cleaner output\n",
    "result_df.replace([float('inf'), -float('inf')], None, inplace=True)\n",
    "\n",
    "# Sort by the absolute difference in clicks (highest impact first)\n",
    "result_df = result_df.sort_values(by='clicks_diff', ascending=False)\n",
    "\n",
    "# Save the result\n",
    "result_df.to_csv('data/category_comparison_jan_feb.csv', index=False)\n",
    "\n",
    "print(f\"Analysis completed. Found {len(result_df)} unique content types.\")\n",
    "print(\"\\nTop 5 categories with biggest click increases:\")\n",
    "print(result_df.head(5)[['content_type', 'clicks_diff', 'clicks_pct_change']])\n",
    "\n",
    "print(\"\\nTop 5 categories with biggest click decreases:\")\n",
    "print(result_df.sort_values(by='clicks_diff')[['content_type', 'clicks_diff', 'clicks_pct_change']].head(5))"
   ],
   "id": "71ecfdd2efe51f24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed. Found 11 unique content types.\n",
      "\n",
      "Top 5 categories with biggest click increases:\n",
      "                       content_type  clicks_diff  clicks_pct_change\n",
      "9              Not_reviewed_brokers       1491.0             324.84\n",
      "10                            Other          5.0               1.86\n",
      "8   Company_name_options_megascaled       -251.0             -22.57\n",
      "6                          Homepage       -528.0             -13.86\n",
      "7                         Education       -664.0             -23.78\n",
      "\n",
      "Top 5 categories with biggest click decreases:\n",
      "        content_type  clicks_diff  clicks_pct_change\n",
      "0      Broker_review     -28412.0             -24.05\n",
      "1               Best     -25503.0             -29.62\n",
      "2  Safety_megascaled      -9695.0             -11.64\n",
      "4       Country_page      -6384.0             -31.54\n",
      "3              Tools      -5188.0             -22.38\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:21:07.614059Z",
     "start_time": "2025-03-12T09:21:07.494473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "jan_df = pd.read_csv('data/gsc-category-t9n-jan.csv')\n",
    "feb_df = pd.read_csv('data/gsc-category-t9n-feb.csv')\n",
    "\n",
    "# Convert percentage strings to numeric values if needed\n",
    "for df in [jan_df, feb_df]:\n",
    "    if df['ctr_percentage'].dtype == 'object':\n",
    "        df['ctr_percentage'] = df['ctr_percentage'].str.replace('%', '').astype(float)\n",
    "    \n",
    "    # Also handle numeric columns with commas if present\n",
    "    for col in ['total_clicks', 'total_impressions', 'unique_urls', 'avg_position']:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.replace(',', '').astype(float)\n",
    "\n",
    "# Create a new dataframe with all unique content types\n",
    "all_categories = pd.concat([jan_df['content_type'], feb_df['content_type']]).unique()\n",
    "result_df = pd.DataFrame({'content_type': all_categories})\n",
    "\n",
    "# Add January data\n",
    "result_df = result_df.merge(\n",
    "    jan_df[['content_type', 'total_clicks', 'total_impressions', 'ctr_percentage', 'avg_position']], \n",
    "    on='content_type', \n",
    "    how='left',\n",
    "    suffixes=('', '_jan')\n",
    ")\n",
    "\n",
    "# Rename columns for January\n",
    "result_df.rename(columns={\n",
    "    'total_clicks': 'jan_clicks',\n",
    "    'total_impressions': 'jan_impressions',\n",
    "    'ctr_percentage': 'jan_ctr',\n",
    "    'avg_position': 'jan_position'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add February data\n",
    "result_df = result_df.merge(\n",
    "    feb_df[['content_type', 'total_clicks', 'total_impressions', 'ctr_percentage', 'avg_position']], \n",
    "    on='content_type', \n",
    "    how='left',\n",
    "    suffixes=('', '_feb')\n",
    ")\n",
    "\n",
    "# Rename columns for February\n",
    "result_df.rename(columns={\n",
    "    'total_clicks': 'feb_clicks',\n",
    "    'total_impressions': 'feb_impressions',\n",
    "    'ctr_percentage': 'feb_ctr',\n",
    "    'avg_position': 'feb_position'\n",
    "}, inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 for categories that don't exist in one of the months\n",
    "result_df = result_df.fillna(0)\n",
    "\n",
    "# Calculate differences\n",
    "result_df['clicks_diff'] = result_df['feb_clicks'] - result_df['jan_clicks']\n",
    "result_df['impressions_diff'] = result_df['feb_impressions'] - result_df['jan_impressions']\n",
    "result_df['ctr_diff'] = result_df['feb_ctr'] - result_df['jan_ctr']\n",
    "result_df['position_diff'] = result_df['jan_position'] - result_df['feb_position']  # Note: Reversed to make positive = improvement\n",
    "\n",
    "# Calculate percentage changes\n",
    "result_df['clicks_pct_change'] = result_df.apply(\n",
    "    lambda x: ((x['feb_clicks'] - x['jan_clicks']) / x['jan_clicks'] * 100) if x['jan_clicks'] > 0 else float('inf'),\n",
    "    axis=1\n",
    ")\n",
    "result_df['impressions_pct_change'] = result_df.apply(\n",
    "    lambda x: ((x['feb_impressions'] - x['jan_impressions']) / x['jan_impressions'] * 100) if x['jan_impressions'] > 0 else float('inf'),\n",
    "    axis=1\n",
    ")\n",
    "result_df['position_pct_change'] = result_df.apply(\n",
    "    lambda x: ((x['jan_position'] - x['feb_position']) / x['jan_position'] * 100) if x['jan_position'] > 0 else float('inf'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Round all numeric columns to 2 decimal places\n",
    "numeric_cols = result_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "result_df[numeric_cols] = result_df[numeric_cols].round(2)\n",
    "\n",
    "# Replace infinity values with None for cleaner output\n",
    "result_df.replace([float('inf'), -float('inf')], None, inplace=True)\n",
    "\n",
    "# Sort by the absolute difference in clicks (highest impact first)\n",
    "result_df = result_df.sort_values(by='clicks_diff', ascending=False)\n",
    "\n",
    "# Save the result\n",
    "result_df.to_csv('data/category_compariso-ngsc-category-t9n.csv', index=False)\n",
    "\n",
    "print(f\"Analysis completed. Found {len(result_df)} unique content types.\")\n",
    "print(\"\\nTop 5 categories with biggest click increases:\")\n",
    "print(result_df.head(5)[['content_type', 'clicks_diff', 'clicks_pct_change']])\n",
    "\n",
    "print(\"\\nTop 5 categories with biggest position improvements:\")\n",
    "print(result_df.sort_values(by='position_diff', ascending=False).head(5)[['content_type', 'jan_position', 'feb_position', 'position_diff']])\n",
    "\n",
    "print(\"\\nTop 5 categories with biggest click decreases:\")\n",
    "print(result_df.sort_values(by='clicks_diff')[['content_type', 'clicks_diff', 'clicks_pct_change']].head(5))"
   ],
   "id": "de560169d16e189c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed. Found 11 unique content types.\n",
      "\n",
      "Top 5 categories with biggest click increases:\n",
      "                       content_type  clicks_diff  clicks_pct_change\n",
      "8              Not_reviewed_brokers       6113.0             403.50\n",
      "9                          Homepage         51.0              16.24\n",
      "10                            Other        -38.0             -33.93\n",
      "7   Company_name_options_megascaled       -496.0             -22.85\n",
      "5                         Education      -1093.0             -16.06\n",
      "\n",
      "Top 5 categories with biggest position improvements:\n",
      "                             content_type  jan_position  feb_position  \\\n",
      "4                                   Tools          8.92          5.76   \n",
      "3   How_to_buy_shares_and_ETFs_megascaled         20.27         19.01   \n",
      "1                           Broker_review         13.09         13.33   \n",
      "10                                  Other         32.74         33.16   \n",
      "0                       Safety_megascaled         11.38         11.87   \n",
      "\n",
      "    position_diff  \n",
      "4            3.16  \n",
      "3            1.26  \n",
      "1           -0.24  \n",
      "10          -0.42  \n",
      "0           -0.49  \n",
      "\n",
      "Top 5 categories with biggest click decreases:\n",
      "                            content_type  clicks_diff  clicks_pct_change\n",
      "1                          Broker_review     -26175.0             -18.83\n",
      "0                      Safety_megascaled     -18157.0             -10.94\n",
      "2                                   Best     -16265.0             -21.82\n",
      "3  How_to_buy_shares_and_ETFs_megascaled      -7118.0             -25.87\n",
      "4                                  Tools      -1635.0             -24.01\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
